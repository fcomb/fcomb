fcomb-server {
  actor-system-name = "fcomb"

  akka {
    logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

    actor {
      provider = "akka.cluster.ClusterActorRefProvider"
    }

    cluster {
      seed-nodes = []
      auto-down-unreachable-after = 10s

      sharding {
        state-store-mode = "ddata"
      }
    }

    # extensions = ["akka.cluster.metrics.ClusterMetricsExtension"]

    http {
      server {
        server-header = "fcomb"
      }
    }

    remote {
      # log-remote-lifecycle-events = off

      netty.tcp {
        hostname = "127.0.0.1"
        port = 0
      }
    }

    persistence {
      journal.plugin = "jdbc-journal"
      snapshot-store.plugin = "jdbc-snapshot-store"
    }
  }

  rest-api {
    interface = "0.0.0.0"
    port = 8080
  }

  jdbc-slick {
    dataSourceClass = "org.postgresql.ds.PGSimpleDataSource"
    maxConnections = 50
    numThreads = 10
  }

  jdbc-journal {
    class = "akka.persistence.jdbc.journal.PostgresqlSyncWriteJournal"
  }

  jdbc-snapshot-store {
    class = "akka.persistence.jdbc.snapshot.PostgresqlSyncSnapshotStore"
  }

  jdbc-connection {
    driverClassName = "org.postgresql.Driver"
    journalSchemaName  = "akka"
    journalTableName   = "journal"
    snapshotSchemaName = "akka"
    snapshotTableName  = "snapshot"
    jndiPath           = ""
    dataSourceName     = ""
    journal-converter  = "akka.persistence.jdbc.serialization.journal.Base64JournalConverter"
    snapshot-converter = "akka.persistence.jdbc.serialization.snapshot.Base64SnapshotConverter"
  }
}

kamon {
  internal-config {
    akka {
      loglevel = DEBUG

      actor.default-dispatcher {
        fork-join-executor.parallelism-factor = 1.0
      }
    }
  }

  newrelic {
    app-name = "fcomb-server"
    license-key = ${?NEW_RELIC_LICENSE_KEY}
  }

  # statsd {
  #   hostname = "statsd"
  # }
}
